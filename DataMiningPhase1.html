<h1 style="color: #5e9ca0;">Search engine for Trending videos on youtube</h1>
<p>Trending videos or most related search can be found using indexing or ranking the result. For Ranking we can use "term frequency(TF)" 
and "inverse document frequency(IDF)" .</p>
<h2 style="color: #2e6c80;">TF-IDF:</h2>
<p>Tf-idf stands for term frequency-inverse document frequency and it is used in information retrieval and text mining. Tf-idf evaluates 
how important a word is to a document in a collection of documents. The importance increases proportionally to the number of times a word 
appears in the document but is offset by the frequency of the word in the corpus. Tf-idf weighting scheme is used by a search engines as a 
central tool in indexing and ranking a document's relevance given a user query.</p>
<h2 style="color: #2e6c80;">TF (Term Frequency):</h2>
<p>TF measures how frequently a term occurs in a document. Since every document is different in length, it is possible that a term would 
appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length 
(aka. the total number of terms in the document) as a way of normalization:</p>
<p>TF of the token or word depends on the document the token belongs to, that is, the same token may have a different weight in different documents.
 Thus, the term frequency is called as local weight.</p>
<h3 style="color: #2e6c80;">TF Calculation Formula:</h3>
<p>TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document)</p>
<div class="card">
	<div class="container">
		<h4>def computeTF(wordDict, bow): <br /> 
		&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tfDict = {} <br /> 
		&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bowCount = len(bow) <br />
		&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for word, count in wordDict.items():<br />
		&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tfDict[word] = count/float(bowCount)<br /> 
		&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return tfDict
		</h4>
	</div>
</div>

<h2 style="color: #2e6c80;">IDF (Inverse Document Frequency):</h2>
<p>IDF measures how important a term is. While computing TF, all terms are considered equally important.
IDF rewards tokens that are rare overall in a dataset. If a rare word occurs in two documents, then it is more important to the meaning of each document. 


<h3 style="color: #2e6c80;">IDF Calculation Formula:</h3>
<p>IDF(t) = log_e(Total number of documents / Number of documents with term t in it)</p>
<h4>def computeIDF(docList):</br>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;import math</br>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;idfDict = {}</br>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;N = len(docList)</br>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;idfDict = dict.fromkeys(docList[0].keys(), 0)</br>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for doc in docList:</br>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for word, val in doc.items():</br>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if val > 0:</br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;idfDict[word] += 1</br>

    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for word, val in idfDict.items():
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;idfDict[word] = math.log10(N/float(val))
</h4>

<h2 style="color: #2e6c80;">TF-IDF:</h2>
<p>TF-IDF weight for a token in a document is the product of its TF and IDF weights. 


<h3 style="color: #2e6c80;">TF-IDF Calculation Formula:</h3>
<p>TF-IDF = TF*IDF</p>
<h4>def computeTfIdf(tfBow, idfs):<br />
	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tfidf = {}<br />
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for word, val in tfBow.items():<br /> 
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tfidf[word] = val*idfs[word]<br />
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return  tfidf<br />
</h4>
<h2 style="color: #2e6c80;">Contributions:</h2>
	<li style="color: #2e6c80;">Removed stop words for an efficient search</li>
	<li style="color: #2e6c80;">Highlighted the search words in the result</li>
	<li style="color: #2e6c80;">Applied stemmer of NLTK for a better search result</li>
<h2 style="color: #2e6c80;">Stop words:</h2>
<p>It is known that certain terms(Stop words), such as "the", "is", "of", and "that", may appear a lot of 
times but have little importance. Thus we need to weigh down the frequent terms while scale up the rare ones.
Remove the stop words while calculation of TF-IDF</p>
<h4>from stop_words import get_stop_words</br>
stop_words = get_stop_words('english')
</h4>
<h2 style="color: #2e6c80;">Highlight the words:</h2>
<p>Highlight the words which are entered in a search query</p>
<h4>for j in detailsOfAllData[ps.stem(i)]:</br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for k in splitTextArray:</br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if j.get("title").find(k) != -1:</br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
j.update(title=re.sub(k, Markup("<mark style = \"background-color: yellow;\">"+k+"</mark>"), j.get('title')))</br>
</h4>
<h2 style="color: #2e6c80;">Apply Stemming(Porter Stemmer):</h2>
<p>Stemming is the process of converting the words of a sentence to its non-changing portions. 
In the example of amusing, amusement, and amused above, the stem would be amus.</p>
<h4>Code:
porter = nltk.PorterStemmer()
stem = [porter.stem(i) for i in tokens]</h4>
<h2 style="color: #2e6c80;">Apply Lemmatization(WordNetLemmatizer):</h2>
<p>Lemmatization is the process of grouping the terms having same meaning. So if you search for the particular term 
then lemmatization will provide you the the result which will be having words with the similar meaning. </p>
<h4>Code:
from nltk.stem import WordNetLemmatizer 
lemmatizer = WordNetLemmatizer() 
lemmatize = [porter.lemmatize(i) for i in tokens]</h4>
<h2 style="color: #2e6c80;">Source Code :</h2>
<a href="https://github.com/prajkta1717/textSearchEngine"></a>
<h2 style="color: #2e6c80;">Challenges faced :</h2>
<li>I started with TF calculation for my dataset. Since my Dataset is quite bigger, my code took time to calculate the TF of every word
of the dataset. While calculating IDF, It took too much time to show the result. To overcome this problem, I did research and found few solutions.
One of them was to use pickle to store the data but after reading articles on it, I came to know that pickle is slow as well as insecured.
Then I used text file to store the TF, IDF and other details. It fetches the data while executing the query.</li>
<li>I have image URLs in my Dataset, No images were in data set then I wrote a code to fetch the image using URL and store it in the system to display it.</li>
<h2 style="color: #2e6c80;">References:</h2>
<li>http://www.tfidf.com/</li>
<li>https://www.quora.com/What-is-difference-between-stemming-and-lemmatization</li>
<li>https://gerardnico.com/natural_language/tf-idf</li>

